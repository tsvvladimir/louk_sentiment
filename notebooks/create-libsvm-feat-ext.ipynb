{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv = Pipeline([\n",
    "        ('vect', CountVectorizer(binary=True)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3893it [00:00, 106450.39it/s]\n",
      "4573it [00:00, 112174.19it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_target = []\n",
    "test_data = []\n",
    "test_target = []\n",
    "with codecs.open('../data/interim/clear_train.csv', 'r') as train_file:\n",
    "    data_reader = csv.reader(train_file)\n",
    "    for row in tqdm(data_reader):\n",
    "        train_data.append(row[0])\n",
    "        train_target.append(float(row[1]))\n",
    "with codecs.open('../data/interim/clear_test.csv', 'r') as test_file:\n",
    "    data_reader = csv.reader(test_file)\n",
    "    for row in tqdm(data_reader):\n",
    "        test_data.append(row[0])\n",
    "        test_target.append(float(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3893, 13722)\n",
      "(4573, 13722)\n"
     ]
    }
   ],
   "source": [
    "train_tfidf = conv.fit_transform(train_data)\n",
    "test_tfidf = conv.transform(test_data)\n",
    "print train_tfidf.shape\n",
    "print test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_cols = ['word', 'pos', 'lemma', 'senti', 'source', 'tes']\n",
    "vocab = pd.read_csv('../data/dict/dict.csv', names=my_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('ru')\n",
    "#print stop_words\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lens = []\n",
    "for line in codecs.open('../data/dict/AFINN-111-ru.txt', 'r'):\n",
    "    lens.append(len(line.split()))\n",
    "from collections import Counter\n",
    "#Counter(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3893it [18:36,  4.14it/s]\n"
     ]
    }
   ],
   "source": [
    "mean_col = []\n",
    "plus_col = []\n",
    "minus_col = []\n",
    "multi_col = []\n",
    "with codecs.open('../data/interim/clear_train.csv', 'r') as train_file:\n",
    "    data_reader = csv.reader(train_file)\n",
    "    i = 0\n",
    "    for idx, row in tqdm(enumerate(data_reader)):\n",
    "        i += 1\n",
    "        text = row[0]\n",
    "        text1 = text.decode('utf-8')\n",
    "        #print text\n",
    "        mean_senti = 0\n",
    "        plus_senti = 0\n",
    "        minus_senti = 0\n",
    "        multi_senti = 0\n",
    "        for idx1, word in enumerate(text1.split()):\n",
    "            #print word\n",
    "            if (word not in stop_words) and (len(word) > 2):\n",
    "                #print word\n",
    "                res = vocab.loc[vocab['lemma'].str.contains(text.split()[idx1])]['senti']\n",
    "                for senti in res:\n",
    "                    #print senti.split()\n",
    "                    if senti.split()[0] == 'positive':\n",
    "                        plus_senti += 1\n",
    "                    if senti.split()[0] == 'negative':\n",
    "                        minus_senti += 1\n",
    "                    if senti.split()[0] == 'positive/negative':\n",
    "                        multi_senti += 1\n",
    "        if (plus_senti > 0) or (minus_senti > 0):\n",
    "            mean_senti = (plus_senti - minus_senti) / (plus_senti + minus_senti)\n",
    "        #print mean_senti, plus_senti, minus_senti, multi_senti\n",
    "        mean_col.append(mean_senti)\n",
    "        plus_col.append(plus_senti)\n",
    "        minus_col.append(minus_senti)\n",
    "        multi_col.append(multi_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3893,)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(mean_col)\n",
    "a = np.array(mean_col)\n",
    "a.shape\n",
    "mean_col1 = np.reshape(a, len(mean_col), -1)\n",
    "mean_col1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3893,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(plus_col)\n",
    "a = np.array(plus_col)\n",
    "plus_col1 = np.reshape(a, len(plus_col), -1)\n",
    "plus_col1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3893,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(minus_col)\n",
    "a = np.array(minus_col)\n",
    "minus_col1 = np.reshape(a, len(minus_col), -1)\n",
    "minus_col1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3893\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print len(multi_col)\n",
    "print multi_col[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array(multi_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3893,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3893,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print a.shape\n",
    "multi_col1 = np.reshape(a, len(multi_col), -1)\n",
    "multi_col1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.insert(len(train_df),'mean', mean_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df.insert(len(train_df),'plus', plus_col)\n",
    "train_df.insert(len(train_df),'minus', minus_col)\n",
    "train_df.insert(len(train_df),'multi', multi_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tfidf = train_df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3893, 13726)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4573it [23:04,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "mean_col = []\n",
    "plus_col = []\n",
    "minus_col = []\n",
    "multi_col = []\n",
    "with codecs.open('../data/interim/clear_test.csv', 'r') as test_file:\n",
    "    data_reader = csv.reader(test_file)\n",
    "    i = 0\n",
    "    for idx, row in tqdm(enumerate(data_reader)):\n",
    "        i += 1\n",
    "        text = row[0]\n",
    "        text1 = text.decode('utf-8')\n",
    "        #print text\n",
    "        mean_senti = 0\n",
    "        plus_senti = 0\n",
    "        minus_senti = 0\n",
    "        multi_senti = 0\n",
    "        for idx1, word in enumerate(text1.split()):\n",
    "            #print word\n",
    "            if (word not in stop_words) and (len(word) > 2):\n",
    "                #print word\n",
    "                res = vocab.loc[vocab['lemma'].str.contains(text.split()[idx1])]['senti']\n",
    "                for senti in res:\n",
    "                    #print senti.split()\n",
    "                    if senti.split()[0] == 'positive':\n",
    "                        plus_senti += 1\n",
    "                    if senti.split()[0] == 'negative':\n",
    "                        minus_senti += 1\n",
    "                    if senti.split()[0] == 'positive/negative':\n",
    "                        multi_senti += 1\n",
    "        if (plus_senti > 0) or (minus_senti > 0):\n",
    "            mean_senti = (plus_senti - minus_senti) / (plus_senti + minus_senti)\n",
    "        #print mean_senti, plus_senti, minus_senti, multi_senti\n",
    "        mean_col.append(mean_senti)\n",
    "        plus_col.append(plus_senti)\n",
    "        minus_col.append(minus_senti)\n",
    "        multi_col.append(multi_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4573, 13726)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test_tfidf.toarray())\n",
    "test_df.insert(len(test_df),'mean', mean_col)\n",
    "test_df.insert(len(test_df),'plus', plus_col)\n",
    "test_df.insert(len(test_df),'minus', minus_col)\n",
    "test_df.insert(len(test_df),'multi', multi_col)\n",
    "test_tfidf = test_df.as_matrix()\n",
    "test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import dump_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_svmlight_file(train_tfidf, train_target, '../data/libsvm/train_tfidf.libsvm')\n",
    "dump_svmlight_file(test_tfidf, test_target, '../data/libsvm/test_tfidf.libsvm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
