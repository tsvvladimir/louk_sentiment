{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import division\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3893it [00:00, 115123.49it/s]\n",
      "4573it [00:00, 75738.22it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_target = []\n",
    "test_data = []\n",
    "test_target = []\n",
    "with codecs.open('../data/interim/clear_train.csv', 'r') as train_file:\n",
    "    data_reader = csv.reader(train_file)\n",
    "    for row in tqdm(data_reader):\n",
    "        train_data.append(row[0])\n",
    "        train_target.append(float(row[1]))\n",
    "with codecs.open('../data/interim/clear_test.csv', 'r') as test_file:\n",
    "    data_reader = csv.reader(test_file)\n",
    "    for row in tqdm(data_reader):\n",
    "        test_data.append(row[0])\n",
    "        test_target.append(float(row[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3893, 13722)\n",
      "(4573, 13722)\n"
     ]
    }
   ],
   "source": [
    "train_tfidf = conv.fit_transform(train_data)\n",
    "test_tfidf = conv.transform(test_data)\n",
    "print train_tfidf.shape\n",
    "print test_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_cols = ['word', 'pos', 'lemma', 'senti', 'source', 'tes']\n",
    "vocab = pd.read_csv('../data/dict/dict.csv', names=my_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>lemma</th>\n",
       "      <th>senti</th>\n",
       "      <th>source</th>\n",
       "      <th>tes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>абортивный</td>\n",
       "      <td>Adj</td>\n",
       "      <td>абортивный</td>\n",
       "      <td>negative</td>\n",
       "      <td>fact</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>аборт</td>\n",
       "      <td>Noun</td>\n",
       "      <td>аборт</td>\n",
       "      <td>negative</td>\n",
       "      <td>fact</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>абракадабра</td>\n",
       "      <td>Noun</td>\n",
       "      <td>абракадабра</td>\n",
       "      <td>negative</td>\n",
       "      <td>opinion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>абсурдность</td>\n",
       "      <td>Noun</td>\n",
       "      <td>абсурдность</td>\n",
       "      <td>negative</td>\n",
       "      <td>opinion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>абсурдный</td>\n",
       "      <td>Adj</td>\n",
       "      <td>абсурдный</td>\n",
       "      <td>negative</td>\n",
       "      <td>opinion</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word    pos         lemma      senti    source  tes\n",
       "0   абортивный    Adj    абортивный   negative      fact  NaN\n",
       "1        аборт   Noun         аборт   negative      fact  NaN\n",
       "2  абракадабра   Noun   абракадабра   negative   opinion  NaN\n",
       "3  абсурдность   Noun   абсурдность   negative   opinion  NaN\n",
       "4    абсурдный    Adj     абсурдный   negative   opinion  NaN"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('ru')\n",
    "#print stop_words\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 5, 2: 2348, 3: 89, 4: 30, 5: 4, 6: 1})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = []\n",
    "for line in codecs.open('../data/dict/AFINN-111-ru.txt', 'r'):\n",
    "    lens.append(len(line.split()))\n",
    "from collections import Counter\n",
    "Counter(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3893it [18:45,  3.37it/s]\n"
     ]
    }
   ],
   "source": [
    "mean_col = []\n",
    "plus_col = []\n",
    "minus_col = []\n",
    "multi_col = []\n",
    "with codecs.open('../data/interim/clear_train.csv', 'r') as train_file:\n",
    "    data_reader = csv.reader(train_file)\n",
    "    i = 0\n",
    "    for idx, row in tqdm(enumerate(data_reader)):\n",
    "        i += 1\n",
    "        text = row[0]\n",
    "        text1 = text.decode('utf-8')\n",
    "        #print text\n",
    "        mean_senti = 0\n",
    "        plus_senti = 0\n",
    "        minus_senti = 0\n",
    "        multi_senti = 0\n",
    "        for idx1, word in enumerate(text1.split()):\n",
    "            #print word\n",
    "            if (word not in stop_words) and (len(word) > 2):\n",
    "                #print word\n",
    "                res = vocab.loc[vocab['lemma'].str.contains(text.split()[idx1])]['senti']\n",
    "                for senti in res:\n",
    "                    #print senti.split()\n",
    "                    if senti.split()[0] == 'positive':\n",
    "                        plus_senti += 1\n",
    "                    if senti.split()[0] == 'negative':\n",
    "                        minus_senti += 1\n",
    "                    if senti.split()[0] == 'positive/negative':\n",
    "                        multi_senti += 1\n",
    "        if (plus_senti > 0) or (minus_senti > 0):\n",
    "            mean_senti = (plus_senti - minus_senti) / (plus_senti + minus_senti)\n",
    "        #print mean_senti, plus_senti, minus_senti, multi_senti\n",
    "        mean_col.append(mean_senti)\n",
    "        plus_col.append(plus_senti)\n",
    "        minus_col.append(minus_senti)\n",
    "        multi_col.append(multi_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array(mean_col)\n",
    "mean_col1 = np.reshape(a, (len(mean_col), -1))\n",
    "a = np.array(plus_col)\n",
    "plus_col1 = np.reshape(a, (len(plus_col), -1))\n",
    "a = np.array(minus_col)\n",
    "minus_col1 = np.reshape(a, (len(minus_col), -1))\n",
    "a = np.array(multi_col)\n",
    "multi_col1 = np.reshape(a, (len(multi_col), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import dump_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dump_svmlight_file(train_tfidf, train_target, '../data/libsvm/train_tfidf.libsvm')\n",
    "dump_svmlight_file(test_tfidf, test_target, '../data/libsvm/test_tfidf.libsvm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
